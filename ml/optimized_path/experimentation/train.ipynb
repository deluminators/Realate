{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07810ff576594dfd91c1a1afc5fb4971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ce257b5ef91543a6912c1ffe6902111e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cd3a6bae78d440d085a88d1e34981e17",
              "IPY_MODEL_14bd7fc2885b4960824ef8d959ae580a",
              "IPY_MODEL_85b4c30416c0409e8387cde1eb384a80"
            ]
          }
        },
        "ce257b5ef91543a6912c1ffe6902111e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd3a6bae78d440d085a88d1e34981e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5495231bd08425a9fa92078b44370b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9a8ea5d21314ecb9649a599d93152b4"
          }
        },
        "14bd7fc2885b4960824ef8d959ae580a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_25676a0a13e94904a8a58171a8b2757c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27d5c9b71b084978aaaa30766430ea88"
          }
        },
        "85b4c30416c0409e8387cde1eb384a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73972e056a30430e8187e56b384eda69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 134MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be8fff7fbd5541feab71a93b7e3014a0"
          }
        },
        "e5495231bd08425a9fa92078b44370b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9a8ea5d21314ecb9649a599d93152b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25676a0a13e94904a8a58171a8b2757c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27d5c9b71b084978aaaa30766430ea88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73972e056a30430e8187e56b384eda69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be8fff7fbd5541feab71a93b7e3014a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "08525c0e"
      },
      "source": [
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "08525c0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "848e017d"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import albumentations as album"
      ],
      "id": "848e017d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "016587a6"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "\n",
        "def downloadImages(url, path):\n",
        "    website = urlopen(url)\n",
        "    html    = website.read()\n",
        "    \n",
        "    bs_parsed = BeautifulSoup(html,\"html5lib\")\n",
        "    \n",
        "    for image_id, link in enumerate(bs_parsed.find_all(\"a\",href=True)):\n",
        "        if image_id == 0:\n",
        "            image_url = link[\"href\"]\n",
        "            if not os.path.isfile(path+\"img-%d.png\"%image_id):\n",
        "                image = Image.open(urlopen(image_url))\n",
        "                image.save(path+\"img-%d.png\" % image_id,\"PNG\")\n",
        "    "
      ],
      "id": "016587a6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6ea571b"
      },
      "source": [
        "os.makedirs('images/train/input')\n",
        "os.makedirs('images/train/target')\n",
        "os.makedirs('images/test/input')\n",
        "os.makedirs('images/test/target')\n",
        "os.makedirs('images/val/input')\n",
        "os.makedirs('images/val/output')\n",
        "TRAIN_IMAGE_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/sat/index.html\"\n",
        "TRAIN_TARGET_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/train/map/index.html\"\n",
        "TEST_IMAGE_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/test/sat/index.html\"\n",
        "TEST_TARGET_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/test/map/index.html\"\n",
        "VAL_IMAGE_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/val/sat/index.html\"\n",
        "VAL_TARGET_URL=\"https://www.cs.toronto.edu/~vmnih/data/mass_roads/val/map/index.html\"\n",
        "downloadImages(url=TRAIN_IMAGE_URL, path=\"images/train/input\")\n",
        "downloadImages(url=TRAIN_TARGET_URL, path=\"images/train/target\")\n",
        "downloadImages(url=TEST_IMAGE_URL, path=\"images/test/input\")\n",
        "downloadImages(url=TEST_TARGET_URL, path=\"images/test/target\")\n",
        "downloadImages(url=VAL_IMAGE_URL, path=\"images/val/input\")\n",
        "downloadImages(url=VAL_TARGET_URL, path=\"images/val/target\")"
      ],
      "id": "d6ea571b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfd4d841"
      },
      "source": [
        "DATA_DIR = '/tiff'\n",
        "\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train_labels')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'val_labels')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test_labels')"
      ],
      "id": "cfd4d841",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75b3fb89"
      },
      "source": [
        "class_names = ['background','road']\n",
        "class_rgb   = [[0,0,0],[255,255,255]]"
      ],
      "id": "75b3fb89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "647eb4ba"
      },
      "source": [
        "def encoder(label,label_values):\n",
        "    semantic_map = []\n",
        "    for color in label_values:\n",
        "        equality     = np.equal(label,color)\n",
        "        class_map    = np.all(equality,axis=-1)\n",
        "        semantic_map.append(class_map)\n",
        "    return np.stack(semantic_map, axis=-1)\n",
        "\n",
        "def decoder(image):\n",
        "    return np.argmax(image,axis=-1)\n",
        "\n",
        "\n",
        "def color_code_seg(image,label_values):\n",
        "    color_codes=np.array(label_values)\n",
        "    return color_codes[image.astype(int)]\n",
        "    "
      ],
      "id": "647eb4ba",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b5b203e"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir, \n",
        "            class_rgb_values=None, \n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        \n",
        "        self.image_paths = [os.path.join(images_dir, image_id) for image_id in sorted(os.listdir(images_dir))]\n",
        "        self.mask_paths = [os.path.join(masks_dir, image_id) for image_id in sorted(os.listdir(masks_dir))]\n",
        "\n",
        "        self.class_rgb_values = class_rgb_values\n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        image = cv2.cvtColor(cv2.imread(self.image_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(cv2.imread(self.mask_paths[i]), cv2.COLOR_BGR2RGB)\n",
        "        mask = encoder(mask, self.class_rgb_values).astype('float')        \n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)"
      ],
      "id": "9b5b203e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5e148f4e"
      },
      "source": [
        "dataset = Dataset(x_train_dir, y_train_dir, class_rgb_values=class_rgb)"
      ],
      "id": "5e148f4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d89c3432"
      },
      "source": [
        "## Training and preprocessing steps from https://www.kaggle.com/balraj98/unet-resnet50-frontend-road-segmentation-pytorch\n",
        "\n",
        "def training_augmentation():\n",
        "    train_transform = [    \n",
        "        album.RandomCrop(height=256, width=256, always_apply=True),\n",
        "        album.OneOf(\n",
        "            [\n",
        "                album.HorizontalFlip(p=1),\n",
        "                album.VerticalFlip(p=1),\n",
        "                album.RandomRotate90(p=1),\n",
        "            ],\n",
        "            p=0.75,\n",
        "        ),\n",
        "    ]\n",
        "    return album.Compose(train_transform)\n",
        "\n",
        "\n",
        "def validation_augmentation():   \n",
        "    test_transform = [\n",
        "        album.PadIfNeeded(min_height=1536, min_width=1536, always_apply=True, border_mode=0),\n",
        "    ]\n",
        "    return album.Compose(test_transform)\n",
        "\n",
        "\n",
        "def to_tensor(x, **kwargs):\n",
        "    return x.transpose(2, 0, 1).astype('float32')\n",
        "\n",
        "\n",
        "def preprocessing(preprocessing_fn=None):\n",
        "    _transform = []\n",
        "    if preprocessing_fn:\n",
        "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
        "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
        "        \n",
        "    return album.Compose(_transform)"
      ],
      "id": "d89c3432",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "521f8202"
      },
      "source": [
        "augmented_dataset = Dataset(\n",
        "    x_train_dir, y_train_dir, \n",
        "    augmentation=training_augmentation(),\n",
        "    class_rgb_values=class_rgb,\n",
        ")"
      ],
      "id": "521f8202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b7bea16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "07810ff576594dfd91c1a1afc5fb4971",
            "ce257b5ef91543a6912c1ffe6902111e",
            "cd3a6bae78d440d085a88d1e34981e17",
            "14bd7fc2885b4960824ef8d959ae580a",
            "85b4c30416c0409e8387cde1eb384a80",
            "e5495231bd08425a9fa92078b44370b9",
            "e9a8ea5d21314ecb9649a599d93152b4",
            "25676a0a13e94904a8a58171a8b2757c",
            "27d5c9b71b084978aaaa30766430ea88",
            "73972e056a30430e8187e56b384eda69",
            "be8fff7fbd5541feab71a93b7e3014a0"
          ]
        },
        "outputId": "31b08279-ca96-4568-9614-a0aaa344d0a8"
      },
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "ENCODER = 'resnet50'\n",
        "ENCODER_WEIGHTS = 'imagenet'\n",
        "CLASSES = class_names\n",
        "ACTIVATION = 'sigmoid' \n",
        "\n",
        "model = smp.Unet(\n",
        "    encoder_name=ENCODER, \n",
        "    encoder_weights=ENCODER_WEIGHTS, \n",
        "    classes=len(CLASSES), \n",
        "    activation=ACTIVATION,\n",
        ")\n",
        "\n",
        "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
      ],
      "id": "2b7bea16",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07810ff576594dfd91c1a1afc5fb4971",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66fdc2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba25e81-6411-4dbf-843f-e1652d18e111"
      },
      "source": [
        "train_dataset = Dataset(\n",
        "    x_train_dir, y_train_dir, \n",
        "    augmentation=training_augmentation(),\n",
        "    preprocessing=preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=class_rgb,\n",
        ")\n",
        "\n",
        "valid_dataset = Dataset(\n",
        "    x_valid_dir, y_valid_dir, \n",
        "    augmentation=validation_augmentation(), \n",
        "    preprocessing=preprocessing(preprocessing_fn),\n",
        "    class_rgb_values=class_rgb,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=4)"
      ],
      "id": "66fdc2eb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08114d8f"
      },
      "source": [
        "EPOCHS = 5\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss = smp.utils.losses.DiceLoss()\n",
        "metrics = [\n",
        "    smp.utils.metrics.IoU(threshold=0.5),\n",
        "]\n",
        "optimizer = torch.optim.Adam([ \n",
        "    dict(params=model.parameters(), lr=0.00008),\n",
        "])\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
        ")"
      ],
      "id": "08114d8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5a6e98a"
      },
      "source": [
        "train_epoch = smp.utils.train.TrainEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "valid_epoch = smp.utils.train.ValidEpoch(\n",
        "    model, \n",
        "    loss=loss, \n",
        "    metrics=metrics, \n",
        "    device=DEVICE,\n",
        "    verbose=True,\n",
        ")"
      ],
      "id": "f5a6e98a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bcb51da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdb2f5aa-9387-4816-9e83-3d947d3e958f"
      },
      "source": [
        "for i in range(0, EPOCHS):\n",
        "  print('\\nEpoch: '+ str(i))\n",
        "  train_logs = train_epoch.run(train_loader)\n",
        "  valid_logs = valid_epoch.run(valid_loader)"
      ],
      "id": "8bcb51da",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0\n",
            "train:   0%|          | 0/70 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 100%|██████████| 70/70 [15:09<00:00, 13.00s/it, dice_loss - 0.3815, iou_score - 0.6017]\n",
            "valid: 100%|██████████| 14/14 [00:16<00:00,  1.16s/it, dice_loss - 0.3532, iou_score - 0.6096]\n",
            "\n",
            "Epoch: 1\n",
            "train: 100%|██████████| 70/70 [17:26<00:00, 14.95s/it, dice_loss - 0.2808, iou_score - 0.8038]\n",
            "valid: 100%|██████████| 14/14 [00:24<00:00,  1.77s/it, dice_loss - 0.2749, iou_score - 0.7981]\n",
            "\n",
            "Epoch: 2\n",
            "train: 100%|██████████| 70/70 [18:47<00:00, 16.11s/it, dice_loss - 0.2305, iou_score - 0.8707]\n",
            "valid: 100%|██████████| 14/14 [00:23<00:00,  1.69s/it, dice_loss - 0.2375, iou_score - 0.826]\n",
            "\n",
            "Epoch: 3\n",
            "train: 100%|██████████| 70/70 [13:17<00:00, 11.40s/it, dice_loss - 0.1948, iou_score - 0.8929]\n",
            "valid: 100%|██████████| 14/14 [00:15<00:00,  1.12s/it, dice_loss - 0.2104, iou_score - 0.8383]\n",
            "\n",
            "Epoch: 4\n",
            "train: 100%|██████████| 70/70 [11:39<00:00,  9.99s/it, dice_loss - 0.166, iou_score - 0.9049]\n",
            "valid: 100%|██████████| 14/14 [00:18<00:00,  1.29s/it, dice_loss - 0.1805, iou_score - 0.854]\n",
            "CPU times: user 3min 25s, sys: 1min 54s, total: 5min 20s\n",
            "Wall time: 1h 17min 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhooQf6-x90i"
      },
      "source": [
        "torch.save(model,\"model.pth\")"
      ],
      "id": "FhooQf6-x90i",
      "execution_count": null,
      "outputs": []
    }
  ]
}